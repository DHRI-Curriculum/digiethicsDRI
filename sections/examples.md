# Level of Impact #3 cont.  

## Activity: Discuss a case example

Check out [the Gender API's website](https://gender-api.com/) and click around its various sections to read about how the API works, and discuss:

* What kinds of information is this API producing?
* Who might be the users of this API? What may be their intentions in using this API?
* Does the use of this API raise any ethical concerns? 

## Activity: Discuss a second case example  

Check out [the Interference Archive'a (IA) website](http://interferencearchive.org/), read [this brief article](http://technical.ly/brooklyn/2016/11/28/interference-archive-activism-jen-hoyer/%20) and discuss:

* What kinds of materials does IA host and do they have rights to it?
* In reference to the article, how does IA see itself as “resisting the hierarchy”?
* What levels of impact does IA aim to take into account?

*Fun fact: I helped paint that #NoDAPL banner - with others at [Decolonize this Place](http://www.decolonizethisplace.org/) - shown in the article's first photo.*

* Relatedly, might public syllabi projects - e.g. the [#StandingRockSyllabus](https://nycstandswithstandingrock.wordpress.com/standingrocksyllabus/) - also be understood as "resisting the hierarchy"? What are some other project examples that attempt this?



The hegemonic racial discourses that associate Blackness with criminality in the United States serve to justify police brutality towards and higher rates of criminalization and mass incarceration of Black people - and these higher rates of policing and incarcerating serve to justify the assumption of their criminality.

So then when, for eample, someone attempts to make an algorithm to identify potential criminals that is produced through machine learning on crime data (e.g. the number of accused crimes in relation to demographic data) that algorithm will reproduce the racist ideologies and practices that police and incarcerate Black people at a much higher rate - an example we will discuss more later.

Further reading: [Julia Angwen & Jeff Larson, "Bias in Criminal Risk Scores Is Mathematically Inevitable, Researchers Say"](https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say)

******

#### Another example:

![A comic from Postcolonial #DH No. 28 by Adeline Koh: "Wikepedia and the politics of gender categorization" - A bunch of white men stand to the left behind a roped off area, and a bunch of people of color and women stand to the right. A white male facing the people to the right says to them, "I'm sorry, there just isn't any more space in the main wikipedia 'American Novelist' category. Maybe you oculd join the 'American Woman Novelist' category?"](wiki.png)  
Image source: A comic by Adeline Koh from [#DHPoco: Postcolonial Digital Humanities](http://dhpoco.tumblr.com/), shared here with her permission. 

Categories are key to digital tools in many ways - the organizational systems used by libraries and archives, the tags used on websites, the methods of categorization informing algorithms - which then shapes not only how things/people/etc are grouped together but what is searchable and findable, and the trajectory of canon formation and what is cited and foregrounded.

... What might be another example of how knowledge is politicized in a digital project?

******

[<<< Back](impact2.md) - [Next >>>](impact3.md)